function [J, grad] = linearRegCostFunction(X, y, theta, lambda)    %Compute cost and gradient for regularized linear regression with multiple variables 
m = length(y);    % number of training examples
h=X*theta;
J = 0;
grad = zeros(size(theta));
J = [sum((h-y).^2)]/(2*m) + [sum(theta(2:size(theta)).^2)]*(lambda/(2*m));
grad = [X'*(h-y) +  lambda*(theta)]/m ;
grad(1) = grad(1) - lambda*theta(1)/m ;
grad = grad(:);
end
