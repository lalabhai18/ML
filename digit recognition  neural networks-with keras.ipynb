{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\admin\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\admin\\\\.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed =128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\admin\\\\Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('.')\n",
    "data_dir = os.path.join(root_dir,'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        filename  label\n",
      "0          0.png      4\n",
      "1          1.png      9\n",
      "2          2.png      1\n",
      "3          3.png      7\n",
      "4          4.png      3\n",
      "5          5.png      9\n",
      "6          6.png      4\n",
      "7          7.png      9\n",
      "8          8.png      3\n",
      "9          9.png      4\n",
      "10        10.png      2\n",
      "11        11.png      3\n",
      "12        12.png      6\n",
      "13        13.png      6\n",
      "14        14.png      0\n",
      "15        15.png      4\n",
      "16        16.png      8\n",
      "17        17.png      7\n",
      "18        18.png      9\n",
      "19        19.png      5\n",
      "20        20.png      3\n",
      "21        21.png      9\n",
      "22        22.png      1\n",
      "23        23.png      9\n",
      "24        24.png      6\n",
      "25        25.png      8\n",
      "26        26.png      9\n",
      "27        27.png      5\n",
      "28        28.png      7\n",
      "29        29.png      3\n",
      "...          ...    ...\n",
      "48970  48970.png      7\n",
      "48971  48971.png      5\n",
      "48972  48972.png      0\n",
      "48973  48973.png      1\n",
      "48974  48974.png      4\n",
      "48975  48975.png      1\n",
      "48976  48976.png      7\n",
      "48977  48977.png      5\n",
      "48978  48978.png      6\n",
      "48979  48979.png      5\n",
      "48980  48980.png      6\n",
      "48981  48981.png      3\n",
      "48982  48982.png      5\n",
      "48983  48983.png      5\n",
      "48984  48984.png      9\n",
      "48985  48985.png      2\n",
      "48986  48986.png      9\n",
      "48987  48987.png      0\n",
      "48988  48988.png      0\n",
      "48989  48989.png      7\n",
      "48990  48990.png      0\n",
      "48991  48991.png      1\n",
      "48992  48992.png      1\n",
      "48993  48993.png      6\n",
      "48994  48994.png      9\n",
      "48995  48995.png      2\n",
      "48996  48996.png      4\n",
      "48997  48997.png      9\n",
      "48998  48998.png      3\n",
      "48999  48999.png      0\n",
      "\n",
      "[49000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANV0lEQVR4nO3df6zV9X3H8dcLvOKKuoAIJZS0naIpMR12t7DNdaWjNUiyoGm6lXSELU6aRrc2bbY6t0T+2WL6Q2vW1Q0rkS7UxrUaycKmlHQjbs5ytYwfMkUtq/wotwYzqNnwAu/9cb80V7zncy/nfM/5nvT9fCQ355zv+/s933dOePE953y+3/NxRAjAz78pTTcAoDcIO5AEYQeSIOxAEoQdSOKCXu7sQk+LizS9l7sEUvk/va434qTHq3UUdtvLJd0raaqkr0fEXaX1L9J0LfGyTnYJoODp2Nay1vbbeNtTJf2NpBskLZS0yvbCdp8PQHd18pl9saQXI+LliHhD0rckraynLQB16yTs8yS9MubxwWrZm9hea3vI9tCITnawOwCd6CTs430J8JZzbyNifUQMRsTggKZ1sDsAnegk7AclzR/z+B2SDnfWDoBu6STsOyQtsP1u2xdK+rikzfW0BaBubQ+9RcQp27dJelyjQ28bImJvbZ0BqFVH4+wRsUXSlpp6AdBFnC4LJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEh3N4op6TFm0sFg/tC6K9R+8f1Pb+77y8bXF+ju/7WJ92pYdbe8bvdVR2G0fkHRC0mlJpyJisI6mANSvjiP7hyLi1RqeB0AX8ZkdSKLTsIekJ2w/Y3vcD3+219oesj00opMd7g5Auzp9G39dRBy2PVvSVtv/FRHbx64QEeslrZekSz2z/E0TgK7p6MgeEYer22FJj0paXEdTAOrXdthtT7d9ydn7kq6XtKeuxgDUq5O38XMkPWr77PN8MyL+uZaufs4c/aNfL9a/+6dfLNZPnCl/+ln1w5Xn3dNZ937gm8X67KUnivXP//GnivWL/vH7590TuqPtsEfEy5J+ucZeAHQRQ29AEoQdSIKwA0kQdiAJwg4kwSWuNXjhb8vnEv3rii8U6wOeWqz/7p2fLdZnPPhUsV7ytfd/tFi/ZdNjxfqVf/FcsX7o8Qtb1mLkjeK2qBdHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2Gky9ZKRYv/PwDcX68EcvKdZnHGp/HH0isWN3sf5nj3yiWN+7+qvF+tKbbm1Zu/jh/yhui3pxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnr8EVn/hBsX54wmco/1xzk2YPnSmvsLpcHn5f6ymfL364jYbQNo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSmDDstjfYHra9Z8yymba32t5f3c7obpsAOjWZI/uDkpafs+x2SdsiYoGkbdVjAH1swrBHxHZJx85ZvFLSxur+Rkk31twXgJq1+5l9TkQckaTqdnarFW2vtT1ke2hEJ9vcHYBOdf0LuohYHxGDETE4oGnd3h2AFtoN+1HbcyWpuh2uryUA3dBu2DdLWlPdXyOpPK8vgMZNeD277YckLZU0y/ZBSXdKukvSw7ZvlvQjSR/rZpPooinlueFP3/xqjxpBt00Y9ohY1aK0rOZeAHQRZ9ABSRB2IAnCDiRB2IEkCDuQBD8lndyUaxYU69vfu6lHnaDbOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsyd3/Opf7OrzX/Ht1tNRR1f3jHNxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnT+7wDac72v4rr11VrHvPiy1rjLP3Fkd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbkZj05UKwPLC9P6fzZGfuL9Yf+4PqWtcvve6q4Leo14ZHd9gbbw7b3jFm2zvYh2zurvxXdbRNApybzNv5BScvHWX5PRCyq/rbU2xaAuk0Y9ojYLulYD3oB0EWdfEF3m+1d1dv8Ga1Wsr3W9pDtoRGd7GB3ADrRbtjvk3SFpEWSjkj6cqsVI2J9RAxGxOCAprW5OwCdaivsEXE0Ik5HxBlJ90taXG9bAOrWVthtzx3z8CZJe1qtC6A/TDjObvshSUslzbJ9UNKdkpbaXqTRS5IPSPpkF3tEF13+yHPF+pJTnyrW33vrrmL9iTu+1LL2kal/Utx29lf/vVjH+Zkw7BGxapzFD3ShFwBdxOmyQBKEHUiCsANJEHYgCcIOJOGI3v2g76WeGUu8rGf7Q/dd8PY5xfo1/3S0Ze1/T5cvr31+cKStnjJ7OrbpeBzzeDWO7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBD8ljY6c+nHrcXRJ+od/W9KytufGvy5u+9vLypfXXrDtmWIdb8aRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJwdXbX6A0+2rA24PB30mQvGvSwbbeLIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM6Ojvzwr36tWH/0sntb1r7y2nuK2/7C918q1k8XqzjXhEd22/Ntf8/2Ptt7bX+6Wj7T9lbb+6vbGd1vF0C7JvM2/pSkz0XEeyT9qqRbbS+UdLukbRGxQNK26jGAPjVh2CPiSEQ8W90/IWmfpHmSVkraWK22UdKN3WoSQOfO6ws62++SdK2kpyXNiYgj0uh/CJJmt9hmre0h20MjOtlZtwDaNumw275Y0nckfSYijk92u4hYHxGDETE4oGnt9AigBpMKu+0BjQZ9U0Q8Ui0+antuVZ8rabg7LQKow4RDb7Yt6QFJ+yLi7jGlzZLWSLqrun2sKx2iq6bOGffT18+8cPe8Yn3nB+8pP3/hMtavPfVbxW2vem1HsY7zM5lx9uskrZa02/bOatkdGg35w7ZvlvQjSR/rTosA6jBh2CPiSUmtfkVgWb3tAOgWTpcFkiDsQBKEHUiCsANJEHYgCS5x7QNT3va2Yv2lDVcW65dtbr39jz9UvhB01tz/Kdb3Xfv1Yl0aKFZ/ZcfvtaxddQvj6L3EkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvR+4PDXx4PxXivWNX/xu27ue0vKCxlFnJth+zYEPF+vz1rV+/omeG/XiyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gfOvP56sf7asvI16Vf/3S0ta89/+P7itn/4ygeL9X/Ze3WxvvAvXy3Wz7z8XLGO3uHIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCLKK9jzJX1D0ts1egny+oi41/Y6SbdI+km16h0RsaX0XJd6ZiwxE78C3fJ0bNPxODbujwhM5qSaU5I+FxHP2r5E0jO2t1a1eyLiS3U1CqB7JjM/+xFJR6r7J2zvkzSv240BqNd5fWa3/S5J10p6ulp0m+1dtjfYntFim7W2h2wPjehkR80CaN+kw277YknfkfSZiDgu6T5JV0hapNEj/5fH2y4i1kfEYEQMDmhaDS0DaMekwm57QKNB3xQRj0hSRByNiNMRcUbS/ZIWd69NAJ2aMOy2LekBSfsi4u4xy+eOWe0mSXvqbw9AXSbzbfx1klZL2m17Z7XsDkmrbC+SFJIOSPpkVzoEUIvJfBv/pDTuj4sXx9QB9BfOoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQx4U9J17oz+yeS/nvMolmSynP+Nqdfe+vXviR6a1edvb0zIi4fr9DTsL9l5/ZQRAw21kBBv/bWr31J9NauXvXG23ggCcIOJNF02Nc3vP+Sfu2tX/uS6K1dPemt0c/sAHqn6SM7gB4h7EASjYTd9nLbz9t+0fbtTfTQiu0Dtnfb3ml7qOFeNtgetr1nzLKZtrfa3l/djjvHXkO9rbN9qHrtdtpe0VBv821/z/Y+23ttf7pa3uhrV+irJ69bzz+z254q6QVJH5F0UNIOSasi4rmeNtKC7QOSBiOi8RMwbP+mpJ9K+kZEXFMt+4KkYxFxV/Uf5YyI+Hyf9LZO0k+bnsa7mq1o7thpxiXdKOn31eBrV+jrd9SD162JI/tiSS9GxMsR8Yakb0la2UAffS8itks6ds7ilZI2Vvc3avQfS8+16K0vRMSRiHi2un9C0tlpxht97Qp99UQTYZ8n6ZUxjw+qv+Z7D0lP2H7G9tqmmxnHnIg4Io3+45E0u+F+zjXhNN69dM40433z2rUz/Xmnmgj7eFNJ9dP433UR8T5JN0i6tXq7ismZ1DTevTLONON9od3pzzvVRNgPSpo/5vE7JB1uoI9xRcTh6nZY0qPqv6moj56dQbe6HW64n5/pp2m8x5tmXH3w2jU5/XkTYd8haYHtd9u+UNLHJW1uoI+3sD29+uJEtqdLul79NxX1ZklrqvtrJD3WYC9v0i/TeLeaZlwNv3aNT38eET3/k7RCo9/IvyTpz5vooUVfvyTpP6u/vU33Jukhjb6tG9HoO6KbJV0maZuk/dXtzD7q7e8l7Za0S6PBmttQb7+h0Y+GuyTtrP5WNP3aFfrqyevG6bJAEpxBByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D9Td+yitfXewgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir,'Images','Train',img_name)\n",
    "img = cv2.imread(filepath,0)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndim(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for image in train.filename:\n",
    "    filepath = os.path.join(data_dir,'Images','Train',image)\n",
    "    img = cv2.imread(filepath,0)\n",
    "    temp.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train = np.array(temp).reshape(49000,28,28,1)\n",
    "y_train = list(train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(width_shift_range = [0.1,0.2])\n",
    "datagen.fit(X_train)\n",
    "for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9, save_to_dir=os.path.join(data_dir,'Images','Train'), save_prefix='aug', save_format='png'):\n",
    "    y_train.append(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49000\n"
     ]
    }
   ],
   "source": [
    "print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.stack(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x) = train_x.reshape(-1,784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(train['label'],num_classes = 10)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_num = int(len(y_train)*0.7)\n",
    "train_x,val_x = train_x[:split_num],train_x[split_num:]\n",
    "train_y,val_y = y_train[:split_num],y_train[split_num:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS WITH 2 LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 7.8684 - acc: 0.5060\n",
      "Epoch 2/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 6.8184 - acc: 0.5741\n",
      "Epoch 3/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 6.7352 - acc: 0.5801\n",
      "Epoch 4/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 6.6807 - acc: 0.5836\n",
      "Epoch 5/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 6.6066 - acc: 0.5883\n",
      "Epoch 6/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 5.4537 - acc: 0.6576\n",
      "Epoch 7/110\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 4.2735 - acc: 0.7314\n",
      "Epoch 8/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 4.1108 - acc: 0.7421\n",
      "Epoch 9/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 3.9522 - acc: 0.7527\n",
      "Epoch 10/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 3.9651 - acc: 0.7510\n",
      "Epoch 11/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 3.8775 - acc: 0.7571\n",
      "Epoch 12/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 3.8804 - acc: 0.7569\n",
      "Epoch 13/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 3.8285 - acc: 0.7602\n",
      "Epoch 14/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 2.6027 - acc: 0.8357\n",
      "Epoch 15/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 2.4148 - acc: 0.8481\n",
      "Epoch 16/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 2.3540 - acc: 0.8515\n",
      "Epoch 17/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 2.3705 - acc: 0.8502\n",
      "Epoch 18/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 2.3205 - acc: 0.8542\n",
      "Epoch 19/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 2.2762 - acc: 0.8569\n",
      "Epoch 20/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 2.2227 - acc: 0.8603\n",
      "Epoch 21/110\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 2.0805 - acc: 0.8687\n",
      "Epoch 22/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 1.1640 - acc: 0.9244\n",
      "Epoch 23/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 1.0176 - acc: 0.9342\n",
      "Epoch 24/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.9445 - acc: 0.9385\n",
      "Epoch 25/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.9048 - acc: 0.9411\n",
      "Epoch 26/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.8607 - acc: 0.9444: 1s - loss: \n",
      "Epoch 27/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.8485 - acc: 0.9451\n",
      "Epoch 28/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.8445 - acc: 0.9455\n",
      "Epoch 29/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.8345 - acc: 0.9462\n",
      "Epoch 30/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7983 - acc: 0.9485\n",
      "Epoch 31/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.8203 - acc: 0.9469\n",
      "Epoch 32/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7679 - acc: 0.9501\n",
      "Epoch 33/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7564 - acc: 0.9511\n",
      "Epoch 34/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.6905 - acc: 0.9556\n",
      "Epoch 35/110\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.7256 - acc: 0.9530\n",
      "Epoch 36/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.6866 - acc: 0.9558\n",
      "Epoch 37/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7082 - acc: 0.9548\n",
      "Epoch 38/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7068 - acc: 0.9543\n",
      "Epoch 39/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7621 - acc: 0.9507\n",
      "Epoch 40/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.7028 - acc: 0.9549\n",
      "Epoch 41/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.6610 - acc: 0.9575\n",
      "Epoch 42/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.6506 - acc: 0.9583\n",
      "Epoch 43/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.6124 - acc: 0.9605\n",
      "Epoch 44/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.6557 - acc: 0.9579\n",
      "Epoch 45/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.6625 - acc: 0.9570\n",
      "Epoch 46/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.6761 - acc: 0.9565\n",
      "Epoch 47/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.6021 - acc: 0.9615\n",
      "Epoch 48/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.5979 - acc: 0.9616\n",
      "Epoch 49/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.5994 - acc: 0.9615\n",
      "Epoch 50/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.6150 - acc: 0.9606\n",
      "Epoch 51/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.6416 - acc: 0.9590\n",
      "Epoch 52/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.7351 - acc: 0.9531\n",
      "Epoch 53/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.6224 - acc: 0.9602\n",
      "Epoch 54/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5963 - acc: 0.9617\n",
      "Epoch 55/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.5893 - acc: 0.9622\n",
      "Epoch 56/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.6396 - acc: 0.9593\n",
      "Epoch 57/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5715 - acc: 0.9634\n",
      "Epoch 58/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5979 - acc: 0.9617\n",
      "Epoch 59/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5737 - acc: 0.9631\n",
      "Epoch 60/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5590 - acc: 0.9642\n",
      "Epoch 61/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5772 - acc: 0.9631\n",
      "Epoch 62/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5933 - acc: 0.9618\n",
      "Epoch 63/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5658 - acc: 0.9639\n",
      "Epoch 64/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.5635 - acc: 0.9640\n",
      "Epoch 65/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.5328 - acc: 0.9658\n",
      "Epoch 66/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5870 - acc: 0.9621\n",
      "Epoch 67/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5534 - acc: 0.9646\n",
      "Epoch 68/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5263 - acc: 0.9665\n",
      "Epoch 69/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5169 - acc: 0.9669\n",
      "Epoch 70/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5387 - acc: 0.9657\n",
      "Epoch 71/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5079 - acc: 0.9677\n",
      "Epoch 72/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5412 - acc: 0.9655\n",
      "Epoch 73/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5488 - acc: 0.9650\n",
      "Epoch 74/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5952 - acc: 0.9622\n",
      "Epoch 75/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5799 - acc: 0.9629\n",
      "Epoch 76/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5640 - acc: 0.9638\n",
      "Epoch 77/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5468 - acc: 0.9652\n",
      "Epoch 78/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5069 - acc: 0.9678\n",
      "Epoch 79/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.5187 - acc: 0.9671\n",
      "Epoch 80/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5081 - acc: 0.9676\n",
      "Epoch 81/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34300/34300 [==============================] - 1s 30us/step - loss: 0.4953 - acc: 0.9685\n",
      "Epoch 82/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5001 - acc: 0.9682\n",
      "Epoch 83/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.5248 - acc: 0.9666\n",
      "Epoch 84/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5056 - acc: 0.9678\n",
      "Epoch 85/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.4782 - acc: 0.9696\n",
      "Epoch 86/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5216 - acc: 0.9668\n",
      "Epoch 87/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.5285 - acc: 0.9663\n",
      "Epoch 88/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5130 - acc: 0.9672\n",
      "Epoch 89/110\n",
      "34300/34300 [==============================] - 1s 31us/step - loss: 0.5068 - acc: 0.9677\n",
      "Epoch 90/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.5156 - acc: 0.9672\n",
      "Epoch 91/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.4761 - acc: 0.9698\n",
      "Epoch 92/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.4910 - acc: 0.9689\n",
      "Epoch 93/110\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.4962 - acc: 0.9685\n",
      "Epoch 94/110\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.4522 - acc: 0.9711\n",
      "Epoch 95/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.4536 - acc: 0.9713\n",
      "Epoch 96/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.5480 - acc: 0.9651\n",
      "Epoch 97/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.4704 - acc: 0.9700\n",
      "Epoch 98/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.4796 - acc: 0.9694\n",
      "Epoch 99/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.4842 - acc: 0.9691\n",
      "Epoch 100/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.5115 - acc: 0.9675\n",
      "Epoch 101/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.4857 - acc: 0.9692\n",
      "Epoch 102/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.4599 - acc: 0.9708\n",
      "Epoch 103/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.4987 - acc: 0.9682\n",
      "Epoch 104/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.4507 - acc: 0.9713\n",
      "Epoch 105/110\n",
      "34300/34300 [==============================] - 1s 32us/step - loss: 0.4388 - acc: 0.9722\n",
      "Epoch 106/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.4530 - acc: 0.9714\n",
      "Epoch 107/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.4891 - acc: 0.9690\n",
      "Epoch 108/110\n",
      "34300/34300 [==============================] - 1s 33us/step - loss: 0.4507 - acc: 0.9716\n",
      "Epoch 109/110\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.4629 - acc: 0.9706\n",
      "Epoch 110/110\n",
      "34300/34300 [==============================] - 1s 34us/step - loss: 0.4687 - acc: 0.9704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2179aa48ac8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "model = Sequential()\n",
    "model.add(Dense(50,activation = 'relu',input_dim = 784))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.fit(train_x,train_y,epochs = 110,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 0s 15us/step\n",
      "[0.7125819161392394, 0.9548299318754754]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(val_x,val_y,batch_size = 128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS WITH 4 LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 6.6314 - acc: 0.5521\n",
      "Epoch 2/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 3.2271 - acc: 0.7538\n",
      "Epoch 3/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 1.5609 - acc: 0.8573\n",
      "Epoch 4/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.4776 - acc: 0.9260\n",
      "Epoch 5/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.3153 - acc: 0.9418\n",
      "Epoch 6/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.2508 - acc: 0.9489\n",
      "Epoch 7/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.2023 - acc: 0.9556\n",
      "Epoch 8/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.1740 - acc: 0.9598\n",
      "Epoch 9/100\n",
      "34300/34300 [==============================] - ETA: 0s - loss: 0.1460 - acc: 0.965 - 1s 39us/step - loss: 0.1453 - acc: 0.9655\n",
      "Epoch 10/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.1309 - acc: 0.9678\n",
      "Epoch 11/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.1155 - acc: 0.9703\n",
      "Epoch 12/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.1179 - acc: 0.9697\n",
      "Epoch 13/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.1042 - acc: 0.9727\n",
      "Epoch 14/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0974 - acc: 0.9746\n",
      "Epoch 15/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.1025 - acc: 0.9738\n",
      "Epoch 16/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0835 - acc: 0.9781\n",
      "Epoch 17/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0857 - acc: 0.9764\n",
      "Epoch 18/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0756 - acc: 0.9795\n",
      "Epoch 19/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0838 - acc: 0.9768\n",
      "Epoch 20/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0779 - acc: 0.9785\n",
      "Epoch 21/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0624 - acc: 0.9825\n",
      "Epoch 22/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0658 - acc: 0.9823\n",
      "Epoch 23/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0686 - acc: 0.9812\n",
      "Epoch 24/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0726 - acc: 0.9792\n",
      "Epoch 25/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0629 - acc: 0.9826\n",
      "Epoch 26/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0584 - acc: 0.9832\n",
      "Epoch 27/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0527 - acc: 0.9859\n",
      "Epoch 28/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0558 - acc: 0.9846\n",
      "Epoch 29/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0491 - acc: 0.9866\n",
      "Epoch 30/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0569 - acc: 0.9841\n",
      "Epoch 31/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0517 - acc: 0.9860\n",
      "Epoch 32/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0486 - acc: 0.9866\n",
      "Epoch 33/100\n",
      "34300/34300 [==============================] - ETA: 0s - loss: 0.0359 - acc: 0.989 - 1s 37us/step - loss: 0.0359 - acc: 0.9891\n",
      "Epoch 34/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0461 - acc: 0.9869\n",
      "Epoch 35/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0453 - acc: 0.9868\n",
      "Epoch 36/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0458 - acc: 0.9878\n",
      "Epoch 37/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0396 - acc: 0.9895\n",
      "Epoch 38/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0306 - acc: 0.9916\n",
      "Epoch 39/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0539 - acc: 0.9853\n",
      "Epoch 40/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0444 - acc: 0.9889\n",
      "Epoch 41/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0378 - acc: 0.9900\n",
      "Epoch 42/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0305 - acc: 0.9912\n",
      "Epoch 43/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0268 - acc: 0.9924\n",
      "Epoch 44/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0401 - acc: 0.9894\n",
      "Epoch 45/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0324 - acc: 0.9914\n",
      "Epoch 46/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0269 - acc: 0.9932\n",
      "Epoch 47/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0368 - acc: 0.9910\n",
      "Epoch 48/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0332 - acc: 0.9905\n",
      "Epoch 49/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0405 - acc: 0.9905\n",
      "Epoch 50/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0393 - acc: 0.9896\n",
      "Epoch 51/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0290 - acc: 0.9921: 1s - loss\n",
      "Epoch 52/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0283 - acc: 0.9930\n",
      "Epoch 53/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0192 - acc: 0.9950\n",
      "Epoch 54/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0266 - acc: 0.9931\n",
      "Epoch 55/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0332 - acc: 0.9912\n",
      "Epoch 56/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0330 - acc: 0.9923\n",
      "Epoch 57/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0327 - acc: 0.9913\n",
      "Epoch 58/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0215 - acc: 0.9941\n",
      "Epoch 59/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0271 - acc: 0.9935\n",
      "Epoch 60/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0204 - acc: 0.9945\n",
      "Epoch 61/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0229 - acc: 0.9945\n",
      "Epoch 62/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0249 - acc: 0.9931\n",
      "Epoch 63/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0306 - acc: 0.9928\n",
      "Epoch 64/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0380 - acc: 0.9910\n",
      "Epoch 65/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0261 - acc: 0.9936\n",
      "Epoch 66/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0235 - acc: 0.9943\n",
      "Epoch 67/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0207 - acc: 0.9947\n",
      "Epoch 68/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0136 - acc: 0.9968\n",
      "Epoch 69/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0168 - acc: 0.9962\n",
      "Epoch 70/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0347 - acc: 0.9916\n",
      "Epoch 71/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0222 - acc: 0.9945\n",
      "Epoch 72/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0196 - acc: 0.9947\n",
      "Epoch 73/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0303 - acc: 0.9928\n",
      "Epoch 74/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0255 - acc: 0.9935\n",
      "Epoch 75/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0184 - acc: 0.9950\n",
      "Epoch 76/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0216 - acc: 0.9948\n",
      "Epoch 77/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0313 - acc: 0.9929\n",
      "Epoch 78/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0326 - acc: 0.9922\n",
      "Epoch 79/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0273 - acc: 0.9935\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0202 - acc: 0.9953\n",
      "Epoch 81/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0220 - acc: 0.9950\n",
      "Epoch 82/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0133 - acc: 0.9971\n",
      "Epoch 83/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0201 - acc: 0.9954\n",
      "Epoch 84/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0401 - acc: 0.9909\n",
      "Epoch 85/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0170 - acc: 0.9955\n",
      "Epoch 86/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0185 - acc: 0.9955\n",
      "Epoch 87/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0168 - acc: 0.9959\n",
      "Epoch 88/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0239 - acc: 0.9941\n",
      "Epoch 89/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0226 - acc: 0.9950\n",
      "Epoch 90/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0216 - acc: 0.9952\n",
      "Epoch 91/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0241 - acc: 0.9948\n",
      "Epoch 92/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0176 - acc: 0.9963\n",
      "Epoch 93/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0190 - acc: 0.9955\n",
      "Epoch 94/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0160 - acc: 0.9964\n",
      "Epoch 95/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0257 - acc: 0.9948\n",
      "Epoch 96/100\n",
      "34300/34300 [==============================] - 1s 38us/step - loss: 0.0346 - acc: 0.9929\n",
      "Epoch 97/100\n",
      "34300/34300 [==============================] - 1s 35us/step - loss: 0.0286 - acc: 0.9943\n",
      "Epoch 98/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0158 - acc: 0.9966\n",
      "Epoch 99/100\n",
      "34300/34300 [==============================] - 1s 36us/step - loss: 0.0148 - acc: 0.9969\n",
      "Epoch 100/100\n",
      "34300/34300 [==============================] - 1s 37us/step - loss: 0.0170 - acc: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2179db95588>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(50,activation = 'relu',input_dim = 784))\n",
    "model1.add(Dense(50,activation = 'relu'))\n",
    "model1.add(Dense(50,activation = 'relu'))\n",
    "model1.add(Dense(10,activation = 'softmax'))\n",
    "model1.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model1.fit(train_x,train_y,epochs = 100,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 1s 47us/step\n",
      "[0.3314332432853736, 0.96224489786187]\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(val_x,val_y,batch_size = 128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS WITH DROPOUT REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "34300/34300 [==============================] - 3s 99us/step - loss: 9.4324 - acc: 0.3769\n",
      "Epoch 2/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 2.8605 - acc: 0.5569\n",
      "Epoch 3/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 1.2373 - acc: 0.6643\n",
      "Epoch 4/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.9782 - acc: 0.7359\n",
      "Epoch 5/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.8356 - acc: 0.7787\n",
      "Epoch 6/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.7497 - acc: 0.8034\n",
      "Epoch 7/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.6786 - acc: 0.8262\n",
      "Epoch 8/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.6248 - acc: 0.8383\n",
      "Epoch 9/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.5787 - acc: 0.8486\n",
      "Epoch 10/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.5556 - acc: 0.8552\n",
      "Epoch 11/110\n",
      "34300/34300 [==============================] - 2s 52us/step - loss: 0.5197 - acc: 0.8634\n",
      "Epoch 12/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.4910 - acc: 0.8714\n",
      "Epoch 13/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.4714 - acc: 0.8758\n",
      "Epoch 14/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.4544 - acc: 0.8783\n",
      "Epoch 15/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.4279 - acc: 0.8838\n",
      "Epoch 16/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.4108 - acc: 0.8908\n",
      "Epoch 17/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.3916 - acc: 0.8956\n",
      "Epoch 18/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.3789 - acc: 0.8982\n",
      "Epoch 19/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.3627 - acc: 0.9034\n",
      "Epoch 20/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.3401 - acc: 0.9092\n",
      "Epoch 21/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.3476 - acc: 0.9066\n",
      "Epoch 22/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.3302 - acc: 0.9099\n",
      "Epoch 23/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.3268 - acc: 0.9118\n",
      "Epoch 24/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.3142 - acc: 0.9152\n",
      "Epoch 25/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.3044 - acc: 0.9186\n",
      "Epoch 26/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.2995 - acc: 0.9188\n",
      "Epoch 27/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.2872 - acc: 0.9222\n",
      "Epoch 28/110\n",
      "34300/34300 [==============================] - 2s 51us/step - loss: 0.2873 - acc: 0.9221\n",
      "Epoch 29/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2906 - acc: 0.9209\n",
      "Epoch 30/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2794 - acc: 0.9240\n",
      "Epoch 31/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2699 - acc: 0.9270\n",
      "Epoch 32/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2695 - acc: 0.9268\n",
      "Epoch 33/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2647 - acc: 0.9289\n",
      "Epoch 34/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.2604 - acc: 0.9310\n",
      "Epoch 35/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2556 - acc: 0.9296\n",
      "Epoch 36/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.2533 - acc: 0.9311\n",
      "Epoch 37/110\n",
      "34300/34300 [==============================] - 2s 52us/step - loss: 0.2502 - acc: 0.9308\n",
      "Epoch 38/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.2497 - acc: 0.9322\n",
      "Epoch 39/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2383 - acc: 0.9345\n",
      "Epoch 40/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.2338 - acc: 0.9369\n",
      "Epoch 41/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2296 - acc: 0.9370\n",
      "Epoch 42/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2298 - acc: 0.9377\n",
      "Epoch 43/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2250 - acc: 0.9391\n",
      "Epoch 44/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.2248 - acc: 0.9387\n",
      "Epoch 45/110\n",
      "34300/34300 [==============================] - 2s 51us/step - loss: 0.2178 - acc: 0.9404\n",
      "Epoch 46/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2160 - acc: 0.9407\n",
      "Epoch 47/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2155 - acc: 0.9407\n",
      "Epoch 48/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2114 - acc: 0.9418\n",
      "Epoch 49/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2085 - acc: 0.9438\n",
      "Epoch 50/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.2110 - acc: 0.9429\n",
      "Epoch 51/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2084 - acc: 0.9435\n",
      "Epoch 52/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.2039 - acc: 0.9441\n",
      "Epoch 53/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1947 - acc: 0.9461\n",
      "Epoch 54/110\n",
      "34300/34300 [==============================] - 2s 51us/step - loss: 0.1942 - acc: 0.9476\n",
      "Epoch 55/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1951 - acc: 0.9470\n",
      "Epoch 56/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1954 - acc: 0.9470\n",
      "Epoch 57/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1988 - acc: 0.9450\n",
      "Epoch 58/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1980 - acc: 0.9452\n",
      "Epoch 59/110\n",
      "34300/34300 [==============================] - 2s 50us/step - loss: 0.1927 - acc: 0.9477\n",
      "Epoch 60/110\n",
      "34300/34300 [==============================] - ETA: 0s - loss: 0.1879 - acc: 0.948 - 2s 53us/step - loss: 0.1875 - acc: 0.9485\n",
      "Epoch 61/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1900 - acc: 0.9481\n",
      "Epoch 62/110\n",
      "34300/34300 [==============================] - 2s 52us/step - loss: 0.1889 - acc: 0.9476\n",
      "Epoch 63/110\n",
      "34300/34300 [==============================] - 2s 52us/step - loss: 0.1933 - acc: 0.9476\n",
      "Epoch 64/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1938 - acc: 0.9469\n",
      "Epoch 65/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1816 - acc: 0.9491\n",
      "Epoch 66/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1798 - acc: 0.9495\n",
      "Epoch 67/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1734 - acc: 0.9529\n",
      "Epoch 68/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1838 - acc: 0.9502\n",
      "Epoch 69/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1814 - acc: 0.9511\n",
      "Epoch 70/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1815 - acc: 0.9502\n",
      "Epoch 71/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1802 - acc: 0.9513\n",
      "Epoch 72/110\n",
      "34300/34300 [==============================] - 2s 51us/step - loss: 0.1784 - acc: 0.9513\n",
      "Epoch 73/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1756 - acc: 0.9531\n",
      "Epoch 74/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1691 - acc: 0.9527\n",
      "Epoch 75/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1717 - acc: 0.9508\n",
      "Epoch 76/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1721 - acc: 0.9535\n",
      "Epoch 77/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1666 - acc: 0.9535\n",
      "Epoch 78/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1757 - acc: 0.9505\n",
      "Epoch 79/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1699 - acc: 0.9535\n",
      "Epoch 80/110\n",
      "34300/34300 [==============================] - 2s 50us/step - loss: 0.1710 - acc: 0.9532\n",
      "Epoch 81/110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1715 - acc: 0.9524\n",
      "Epoch 82/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1703 - acc: 0.9538\n",
      "Epoch 83/110\n",
      "34300/34300 [==============================] - 2s 57us/step - loss: 0.1711 - acc: 0.9527\n",
      "Epoch 84/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1668 - acc: 0.9545\n",
      "Epoch 85/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1630 - acc: 0.9554\n",
      "Epoch 86/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1677 - acc: 0.9535\n",
      "Epoch 87/110\n",
      "34300/34300 [==============================] - 2s 57us/step - loss: 0.1717 - acc: 0.9540\n",
      "Epoch 88/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1585 - acc: 0.9566\n",
      "Epoch 89/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1623 - acc: 0.9556\n",
      "Epoch 90/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1654 - acc: 0.9548\n",
      "Epoch 91/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1603 - acc: 0.9555\n",
      "Epoch 92/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1585 - acc: 0.9559\n",
      "Epoch 93/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1534 - acc: 0.9570\n",
      "Epoch 94/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1653 - acc: 0.9543\n",
      "Epoch 95/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1605 - acc: 0.9578\n",
      "Epoch 96/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1556 - acc: 0.9588\n",
      "Epoch 97/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1524 - acc: 0.9596\n",
      "Epoch 98/110\n",
      "34300/34300 [==============================] - 2s 56us/step - loss: 0.1567 - acc: 0.9580\n",
      "Epoch 99/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1536 - acc: 0.9577\n",
      "Epoch 100/110\n",
      "34300/34300 [==============================] - ETA: 0s - loss: 0.1487 - acc: 0.959 - 2s 54us/step - loss: 0.1485 - acc: 0.9598\n",
      "Epoch 101/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1509 - acc: 0.9583\n",
      "Epoch 102/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1467 - acc: 0.9606\n",
      "Epoch 103/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1536 - acc: 0.9584\n",
      "Epoch 104/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1507 - acc: 0.9583\n",
      "Epoch 105/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1453 - acc: 0.9598\n",
      "Epoch 106/110\n",
      "34300/34300 [==============================] - 2s 53us/step - loss: 0.1467 - acc: 0.9594\n",
      "Epoch 107/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1581 - acc: 0.9578\n",
      "Epoch 108/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1510 - acc: 0.9582\n",
      "Epoch 109/110\n",
      "34300/34300 [==============================] - 2s 54us/step - loss: 0.1502 - acc: 0.9591\n",
      "Epoch 110/110\n",
      "34300/34300 [==============================] - 2s 55us/step - loss: 0.1444 - acc: 0.9601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217ad753748>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50,activation = 'relu',input_dim = 784))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(50,activation = 'relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(50,activation = 'relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(10,activation = 'softmax'))\n",
    "model2.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model2.fit(train_x,train_y,epochs = 110,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 1s 63us/step\n",
      "[0.22678488183791945, 0.9516326531423193]\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(val_x,val_y,batch_size = 128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEYRAL NETWORKS WITH HE INITIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34300/34300 [==============================] - 3s 91us/step - loss: 4.3844 - acc: 0.6932\n",
      "Epoch 2/100\n",
      "34300/34300 [==============================] - 2s 46us/step - loss: 1.3432 - acc: 0.8937\n",
      "Epoch 3/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 1.0106 - acc: 0.9163\n",
      "Epoch 4/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.7961 - acc: 0.9310\n",
      "Epoch 5/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.7023 - acc: 0.9391\n",
      "Epoch 6/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.6006 - acc: 0.9435\n",
      "Epoch 7/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.5253 - acc: 0.9496\n",
      "Epoch 8/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.5109 - acc: 0.9508\n",
      "Epoch 9/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.4363 - acc: 0.9569\n",
      "Epoch 10/100\n",
      "34300/34300 [==============================] - 2s 44us/step - loss: 0.3599 - acc: 0.9614\n",
      "Epoch 11/100\n",
      "34300/34300 [==============================] - 2s 45us/step - loss: 0.3070 - acc: 0.9638\n",
      "Epoch 12/100\n",
      "34300/34300 [==============================] - 2s 47us/step - loss: 0.2813 - acc: 0.9660\n",
      "Epoch 13/100\n",
      "34300/34300 [==============================] - 1s 44us/step - loss: 0.2474 - acc: 0.9683\n",
      "Epoch 14/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.2215 - acc: 0.9692\n",
      "Epoch 15/100\n",
      "34300/34300 [==============================] - 2s 45us/step - loss: 0.1884 - acc: 0.9731\n",
      "Epoch 16/100\n",
      "34300/34300 [==============================] - 2s 45us/step - loss: 0.1733 - acc: 0.9742\n",
      "Epoch 17/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.1556 - acc: 0.9760\n",
      "Epoch 18/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.1349 - acc: 0.9772\n",
      "Epoch 19/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.1369 - acc: 0.9759\n",
      "Epoch 20/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.1160 - acc: 0.9801\n",
      "Epoch 21/100\n",
      "34300/34300 [==============================] - 1s 44us/step - loss: 0.1037 - acc: 0.9814\n",
      "Epoch 22/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.0993 - acc: 0.9827\n",
      "Epoch 23/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0896 - acc: 0.9840\n",
      "Epoch 24/100\n",
      "34300/34300 [==============================] - 2s 44us/step - loss: 0.0904 - acc: 0.9822\n",
      "Epoch 25/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0883 - acc: 0.9828\n",
      "Epoch 26/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0751 - acc: 0.9847\n",
      "Epoch 27/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0832 - acc: 0.9836\n",
      "Epoch 28/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0752 - acc: 0.9850\n",
      "Epoch 29/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0789 - acc: 0.9841\n",
      "Epoch 30/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0879 - acc: 0.9817\n",
      "Epoch 31/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0807 - acc: 0.9828\n",
      "Epoch 32/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.0607 - acc: 0.9876\n",
      "Epoch 33/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0616 - acc: 0.9865\n",
      "Epoch 34/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0635 - acc: 0.9860\n",
      "Epoch 35/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0712 - acc: 0.9852\n",
      "Epoch 36/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0630 - acc: 0.9856\n",
      "Epoch 37/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0521 - acc: 0.9883\n",
      "Epoch 38/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0473 - acc: 0.9892\n",
      "Epoch 39/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0420 - acc: 0.9906\n",
      "Epoch 40/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0313 - acc: 0.9924\n",
      "Epoch 41/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0330 - acc: 0.9921\n",
      "Epoch 42/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0451 - acc: 0.9898\n",
      "Epoch 43/100\n",
      "34300/34300 [==============================] - 1s 44us/step - loss: 0.0531 - acc: 0.9875\n",
      "Epoch 44/100\n",
      "34300/34300 [==============================] - 2s 45us/step - loss: 0.0506 - acc: 0.9887\n",
      "Epoch 45/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0447 - acc: 0.9891\n",
      "Epoch 46/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0450 - acc: 0.9891: 1s - lo\n",
      "Epoch 47/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0333 - acc: 0.9918\n",
      "Epoch 48/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0319 - acc: 0.9930\n",
      "Epoch 49/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0410 - acc: 0.9898\n",
      "Epoch 50/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0370 - acc: 0.9913\n",
      "Epoch 51/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.0412 - acc: 0.9906\n",
      "Epoch 52/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0351 - acc: 0.9924\n",
      "Epoch 53/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0351 - acc: 0.9922\n",
      "Epoch 54/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0252 - acc: 0.9947\n",
      "Epoch 55/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0390 - acc: 0.9906\n",
      "Epoch 56/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0251 - acc: 0.9940\n",
      "Epoch 57/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0425 - acc: 0.9903\n",
      "Epoch 58/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0366 - acc: 0.9913\n",
      "Epoch 59/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0276 - acc: 0.9934\n",
      "Epoch 60/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0286 - acc: 0.9928\n",
      "Epoch 61/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0321 - acc: 0.9929\n",
      "Epoch 62/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0265 - acc: 0.9941\n",
      "Epoch 63/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0264 - acc: 0.9939\n",
      "Epoch 64/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0273 - acc: 0.9938\n",
      "Epoch 65/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0238 - acc: 0.9947\n",
      "Epoch 66/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.0349 - acc: 0.9916\n",
      "Epoch 67/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0325 - acc: 0.9931\n",
      "Epoch 68/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0271 - acc: 0.9935\n",
      "Epoch 69/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0277 - acc: 0.9934\n",
      "Epoch 70/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0234 - acc: 0.9948\n",
      "Epoch 71/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0278 - acc: 0.9939\n",
      "Epoch 72/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0341 - acc: 0.9927\n",
      "Epoch 73/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0309 - acc: 0.9933\n",
      "Epoch 74/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0234 - acc: 0.9949\n",
      "Epoch 75/100\n",
      "34300/34300 [==============================] - 1s 39us/step - loss: 0.0301 - acc: 0.9933\n",
      "Epoch 76/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0253 - acc: 0.9943\n",
      "Epoch 77/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0171 - acc: 0.9964\n",
      "Epoch 78/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0217 - acc: 0.9948: 0s - loss: 0.0192 - ac\n",
      "Epoch 79/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0405 - acc: 0.9910\n",
      "Epoch 80/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0336 - acc: 0.9934\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0387 - acc: 0.9920\n",
      "Epoch 82/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0279 - acc: 0.9940\n",
      "Epoch 83/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0147 - acc: 0.9970\n",
      "Epoch 84/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0208 - acc: 0.9961\n",
      "Epoch 85/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0211 - acc: 0.9958\n",
      "Epoch 86/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0239 - acc: 0.9946\n",
      "Epoch 87/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0278 - acc: 0.9940\n",
      "Epoch 88/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0205 - acc: 0.9956\n",
      "Epoch 89/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.0311 - acc: 0.9931\n",
      "Epoch 90/100\n",
      "34300/34300 [==============================] - 1s 43us/step - loss: 0.0222 - acc: 0.9947\n",
      "Epoch 91/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0188 - acc: 0.9957\n",
      "Epoch 92/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0118 - acc: 0.9979\n",
      "Epoch 93/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0128 - acc: 0.9975\n",
      "Epoch 94/100\n",
      "34300/34300 [==============================] - 1s 42us/step - loss: 0.0277 - acc: 0.9946\n",
      "Epoch 95/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0546 - acc: 0.9891\n",
      "Epoch 96/100\n",
      "34300/34300 [==============================] - 1s 41us/step - loss: 0.0254 - acc: 0.9942\n",
      "Epoch 97/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0121 - acc: 0.9980\n",
      "Epoch 98/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0111 - acc: 0.9980ETA: 1s - los\n",
      "Epoch 99/100\n",
      "34300/34300 [==============================] - 1s 40us/step - loss: 0.0150 - acc: 0.9973\n",
      "Epoch 100/100\n",
      "34300/34300 [==============================] - 2s 45us/step - loss: 0.0343 - acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217af29efd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(50,activation = 'relu',input_dim = 784,kernel_initializer = 'he_normal'))\n",
    "model1.add(Dense(50,activation = 'relu'))\n",
    "model1.add(Dense(50,activation = 'relu'))\n",
    "model1.add(Dense(10,activation = 'softmax'))\n",
    "model1.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model1.fit(train_x,train_y,epochs = 100,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 1s 54us/step\n",
      "[0.32406309570179503, 0.959319728053346]\n"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(val_x,val_y,batch_size = 128)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS WITH BATCH NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34300/34300 [==============================] - 5s 154us/step - loss: 0.5178 - acc: 0.8473\n",
      "Epoch 2/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.1792 - acc: 0.9474\n",
      "Epoch 3/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.1261 - acc: 0.9627\n",
      "Epoch 4/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0979 - acc: 0.9699\n",
      "Epoch 5/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0797 - acc: 0.9757\n",
      "Epoch 6/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0653 - acc: 0.9795\n",
      "Epoch 7/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0544 - acc: 0.9833\n",
      "Epoch 8/100\n",
      "34300/34300 [==============================] - 2s 68us/step - loss: 0.0468 - acc: 0.9852\n",
      "Epoch 9/100\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.0403 - acc: 0.9869\n",
      "Epoch 10/100\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.0345 - acc: 0.9890\n",
      "Epoch 11/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0296 - acc: 0.9908\n",
      "Epoch 12/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0292 - acc: 0.9905\n",
      "Epoch 13/100\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.0253 - acc: 0.9917\n",
      "Epoch 14/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0216 - acc: 0.9930\n",
      "Epoch 15/100\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.0229 - acc: 0.9922\n",
      "Epoch 16/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0226 - acc: 0.9925\n",
      "Epoch 17/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0187 - acc: 0.9934\n",
      "Epoch 18/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0160 - acc: 0.9948\n",
      "Epoch 19/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0167 - acc: 0.9944\n",
      "Epoch 20/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0176 - acc: 0.9944\n",
      "Epoch 21/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0164 - acc: 0.9945\n",
      "Epoch 22/100\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.0129 - acc: 0.9955\n",
      "Epoch 23/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 24/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0154 - acc: 0.9948\n",
      "Epoch 25/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0139 - acc: 0.9948\n",
      "Epoch 26/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0131 - acc: 0.9955\n",
      "Epoch 27/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0139 - acc: 0.9952\n",
      "Epoch 28/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0135 - acc: 0.9955\n",
      "Epoch 29/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 30/100\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.0095 - acc: 0.9968\n",
      "Epoch 31/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 32/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 33/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0107 - acc: 0.9963\n",
      "Epoch 34/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 35/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 36/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0098 - acc: 0.9968\n",
      "Epoch 37/100\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.0075 - acc: 0.9973\n",
      "Epoch 38/100\n",
      "34300/34300 [==============================] - 2s 68us/step - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 39/100\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 40/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0104 - acc: 0.9966\n",
      "Epoch 41/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 42/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 43/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 44/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 45/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0113 - acc: 0.9959\n",
      "Epoch 46/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0077 - acc: 0.9972\n",
      "Epoch 47/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 48/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0082 - acc: 0.9971\n",
      "Epoch 49/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0101 - acc: 0.9964\n",
      "Epoch 50/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0081 - acc: 0.9968\n",
      "Epoch 51/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0075 - acc: 0.9975\n",
      "Epoch 52/100\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.0046 - acc: 0.9983\n",
      "Epoch 53/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0055 - acc: 0.9981\n",
      "Epoch 54/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0059 - acc: 0.9981\n",
      "Epoch 55/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0082 - acc: 0.9971\n",
      "Epoch 56/100\n",
      "34300/34300 [==============================] - 2s 60us/step - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 57/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0067 - acc: 0.9977\n",
      "Epoch 58/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0076 - acc: 0.9972\n",
      "Epoch 59/100\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.0069 - acc: 0.9975\n",
      "Epoch 60/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0068 - acc: 0.9976\n",
      "Epoch 61/100\n",
      "34300/34300 [==============================] - 2s 60us/step - loss: 0.0054 - acc: 0.9982\n",
      "Epoch 62/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 63/100\n",
      "34300/34300 [==============================] - 2s 60us/step - loss: 0.0051 - acc: 0.9983\n",
      "Epoch 64/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0070 - acc: 0.9976\n",
      "Epoch 65/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0053 - acc: 0.9981\n",
      "Epoch 66/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0057 - acc: 0.9982\n",
      "Epoch 67/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0040 - acc: 0.9987\n",
      "Epoch 68/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0037 - acc: 0.9988\n",
      "Epoch 69/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 70/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0056 - acc: 0.9982: 1s\n",
      "Epoch 71/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0068 - acc: 0.9979\n",
      "Epoch 72/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0090 - acc: 0.9972\n",
      "Epoch 73/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0068 - acc: 0.9977\n",
      "Epoch 74/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 75/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0037 - acc: 0.9987\n",
      "Epoch 76/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 77/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 78/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 79/100\n",
      "34300/34300 [==============================] - 2s 61us/step - loss: 0.0050 - acc: 0.9983\n",
      "Epoch 80/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0060 - acc: 0.9978\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0080 - acc: 0.9970\n",
      "Epoch 82/100\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.0054 - acc: 0.9982\n",
      "Epoch 83/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 84/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 85/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 86/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0043 - acc: 0.9985\n",
      "Epoch 87/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0041 - acc: 0.9986\n",
      "Epoch 88/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 89/100\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.0055 - acc: 0.9980\n",
      "Epoch 90/100\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 91/100\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.0037 - acc: 0.9987\n",
      "Epoch 92/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0045 - acc: 0.9987\n",
      "Epoch 93/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 94/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 95/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 96/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 97/100\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.0054 - acc: 0.9980\n",
      "Epoch 98/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0054 - acc: 0.9980\n",
      "Epoch 99/100\n",
      "34300/34300 [==============================] - 2s 62us/step - loss: 0.0063 - acc: 0.9980\n",
      "Epoch 100/100\n",
      "34300/34300 [==============================] - 2s 63us/step - loss: 0.0055 - acc: 0.9983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217b194de48>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(50,activation = 'relu',input_dim = 784,kernel_initializer = 'he_normal'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(50,activation = 'relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(50,activation = 'relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(10,activation = 'softmax'))\n",
    "model4.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model4.fit(train_x,train_y,epochs = 100,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 1s 72us/step\n",
      "[0.1721432804985314, 0.9699319729513052]\n"
     ]
    }
   ],
   "source": [
    "score = model4.evaluate(val_x,val_y,batch_size = 128)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
