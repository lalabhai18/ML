{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORKS WITH DROPOUT REGULARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34300 samples, validate on 14700 samples\n",
      "Epoch 1/110\n",
      "34300/34300 [==============================] - 5s 141us/step - loss: 9.2449 - acc: 0.3979 - val_loss: 4.1312 - val_acc: 0.7174\n",
      "Epoch 2/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 4.5822 - acc: 0.6588 - val_loss: 1.4457 - val_acc: 0.7722\n",
      "Epoch 3/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 1.4214 - acc: 0.6423 - val_loss: 0.9128 - val_acc: 0.7522\n",
      "Epoch 4/110\n",
      "34300/34300 [==============================] - 2s 73us/step - loss: 1.0263 - acc: 0.7188 - val_loss: 0.7222 - val_acc: 0.8264\n",
      "Epoch 5/110\n",
      "34300/34300 [==============================] - 2s 73us/step - loss: 0.8543 - acc: 0.7730 - val_loss: 0.6459 - val_acc: 0.8548\n",
      "Epoch 6/110\n",
      "34300/34300 [==============================] - 3s 75us/step - loss: 0.7527 - acc: 0.7988 - val_loss: 0.5527 - val_acc: 0.8714\n",
      "Epoch 7/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.6763 - acc: 0.8201 - val_loss: 0.4815 - val_acc: 0.8944\n",
      "Epoch 8/110\n",
      "34300/34300 [==============================] - 3s 75us/step - loss: 0.6246 - acc: 0.8313 - val_loss: 0.4597 - val_acc: 0.8978\n",
      "Epoch 9/110\n",
      "34300/34300 [==============================] - 2s 73us/step - loss: 0.5889 - acc: 0.8396 - val_loss: 0.4260 - val_acc: 0.9045\n",
      "Epoch 10/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.5490 - acc: 0.8480 - val_loss: 0.3901 - val_acc: 0.9112\n",
      "Epoch 11/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.5197 - acc: 0.8531 - val_loss: 0.3836 - val_acc: 0.9118\n",
      "Epoch 12/110\n",
      "34300/34300 [==============================] - 3s 75us/step - loss: 0.4952 - acc: 0.8618 - val_loss: 0.3618 - val_acc: 0.9183\n",
      "Epoch 13/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.4779 - acc: 0.8643 - val_loss: 0.3468 - val_acc: 0.9209\n",
      "Epoch 14/110\n",
      "34300/34300 [==============================] - 3s 74us/step - loss: 0.4425 - acc: 0.8717 - val_loss: 0.3235 - val_acc: 0.9200\n",
      "Epoch 15/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.4344 - acc: 0.8749 - val_loss: 0.3285 - val_acc: 0.9216\n",
      "Epoch 16/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.4048 - acc: 0.8847 - val_loss: 0.2969 - val_acc: 0.9271\n",
      "Epoch 17/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.4046 - acc: 0.8886 - val_loss: 0.3013 - val_acc: 0.9288\n",
      "Epoch 18/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.3763 - acc: 0.8971 - val_loss: 0.3141 - val_acc: 0.9261\n",
      "Epoch 19/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.3665 - acc: 0.8987 - val_loss: 0.2872 - val_acc: 0.9310\n",
      "Epoch 20/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.3469 - acc: 0.9041 - val_loss: 0.2626 - val_acc: 0.9327\n",
      "Epoch 21/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.3348 - acc: 0.9075 - val_loss: 0.2698 - val_acc: 0.9331\n",
      "Epoch 22/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.3313 - acc: 0.9083 - val_loss: 0.2616 - val_acc: 0.9331\n",
      "Epoch 23/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.3206 - acc: 0.9124 - val_loss: 0.2655 - val_acc: 0.9327\n",
      "Epoch 24/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.3143 - acc: 0.9128 - val_loss: 0.2497 - val_acc: 0.9378\n",
      "Epoch 25/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.3093 - acc: 0.9142 - val_loss: 0.2519 - val_acc: 0.9365\n",
      "Epoch 26/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.2932 - acc: 0.9192 - val_loss: 0.2556 - val_acc: 0.9342\n",
      "Epoch 27/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2940 - acc: 0.9187 - val_loss: 0.2458 - val_acc: 0.9339\n",
      "Epoch 28/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2873 - acc: 0.9214 - val_loss: 0.2399 - val_acc: 0.9371\n",
      "Epoch 29/110\n",
      "34300/34300 [==============================] - 2s 68us/step - loss: 0.2729 - acc: 0.9230 - val_loss: 0.2473 - val_acc: 0.9401\n",
      "Epoch 30/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2785 - acc: 0.9226 - val_loss: 0.2489 - val_acc: 0.9404\n",
      "Epoch 31/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2703 - acc: 0.9249 - val_loss: 0.2356 - val_acc: 0.9421\n",
      "Epoch 32/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.2678 - acc: 0.9262 - val_loss: 0.2247 - val_acc: 0.9435\n",
      "Epoch 33/110\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.2613 - acc: 0.9265 - val_loss: 0.2450 - val_acc: 0.9395\n",
      "Epoch 34/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.2658 - acc: 0.9261 - val_loss: 0.2301 - val_acc: 0.9428\n",
      "Epoch 35/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.2557 - acc: 0.9286 - val_loss: 0.2304 - val_acc: 0.9424\n",
      "Epoch 36/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.2538 - acc: 0.9279 - val_loss: 0.2360 - val_acc: 0.9415\n",
      "Epoch 37/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2490 - acc: 0.9303 - val_loss: 0.2256 - val_acc: 0.9431\n",
      "Epoch 38/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2514 - acc: 0.9299 - val_loss: 0.2261 - val_acc: 0.9428\n",
      "Epoch 39/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.2444 - acc: 0.9323 - val_loss: 0.2280 - val_acc: 0.9451\n",
      "Epoch 40/110\n",
      "34300/34300 [==============================] - 2s 66us/step - loss: 0.2411 - acc: 0.9307 - val_loss: 0.2189 - val_acc: 0.9456\n",
      "Epoch 41/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2409 - acc: 0.9319 - val_loss: 0.2285 - val_acc: 0.9431\n",
      "Epoch 42/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2376 - acc: 0.9329 - val_loss: 0.2291 - val_acc: 0.9432\n",
      "Epoch 43/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.2368 - acc: 0.9348 - val_loss: 0.2232 - val_acc: 0.9422\n",
      "Epoch 44/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2360 - acc: 0.9336 - val_loss: 0.2176 - val_acc: 0.9458\n",
      "Epoch 45/110\n",
      "34300/34300 [==============================] - 3s 74us/step - loss: 0.2317 - acc: 0.9355 - val_loss: 0.2259 - val_acc: 0.9420\n",
      "Epoch 46/110\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.2291 - acc: 0.9347 - val_loss: 0.2181 - val_acc: 0.9460\n",
      "Epoch 47/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2307 - acc: 0.9365 - val_loss: 0.2124 - val_acc: 0.9463\n",
      "Epoch 48/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2209 - acc: 0.9383 - val_loss: 0.2231 - val_acc: 0.9433\n",
      "Epoch 49/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2159 - acc: 0.9397 - val_loss: 0.2191 - val_acc: 0.9476\n",
      "Epoch 50/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2153 - acc: 0.9392 - val_loss: 0.2150 - val_acc: 0.9460\n",
      "Epoch 51/110\n",
      "34300/34300 [==============================] - 3s 74us/step - loss: 0.2166 - acc: 0.9389 - val_loss: 0.2130 - val_acc: 0.9480\n",
      "Epoch 52/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.2105 - acc: 0.9412 - val_loss: 0.2107 - val_acc: 0.9461\n",
      "Epoch 53/110\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.2172 - acc: 0.9381 - val_loss: 0.2112 - val_acc: 0.9461\n",
      "Epoch 54/110\n",
      "34300/34300 [==============================] - 2s 64us/step - loss: 0.2125 - acc: 0.9410 - val_loss: 0.2066 - val_acc: 0.9493\n",
      "Epoch 55/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2150 - acc: 0.9393 - val_loss: 0.2126 - val_acc: 0.9476\n",
      "Epoch 56/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.2080 - acc: 0.9413 - val_loss: 0.2329 - val_acc: 0.9442\n",
      "Epoch 57/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2040 - acc: 0.9434 - val_loss: 0.2261 - val_acc: 0.9460\n",
      "Epoch 58/110\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.2017 - acc: 0.9431 - val_loss: 0.2262 - val_acc: 0.9465\n",
      "Epoch 59/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.2068 - acc: 0.9431 - val_loss: 0.2257 - val_acc: 0.9471\n",
      "Epoch 60/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.2056 - acc: 0.9417 - val_loss: 0.2155 - val_acc: 0.9473\n",
      "Epoch 61/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1985 - acc: 0.9444 - val_loss: 0.2210 - val_acc: 0.9471\n",
      "Epoch 62/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1984 - acc: 0.9440 - val_loss: 0.2217 - val_acc: 0.9462\n",
      "Epoch 63/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1984 - acc: 0.9444 - val_loss: 0.2171 - val_acc: 0.9463\n",
      "Epoch 64/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.2045 - acc: 0.9433 - val_loss: 0.2093 - val_acc: 0.9492\n",
      "Epoch 65/110\n",
      "34300/34300 [==============================] - 3s 73us/step - loss: 0.1933 - acc: 0.9449 - val_loss: 0.2262 - val_acc: 0.9474\n",
      "Epoch 66/110\n",
      "34300/34300 [==============================] - 2s 68us/step - loss: 0.1953 - acc: 0.9442 - val_loss: 0.2333 - val_acc: 0.9458\n",
      "Epoch 67/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1970 - acc: 0.9472 - val_loss: 0.2294 - val_acc: 0.9480\n",
      "Epoch 68/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1967 - acc: 0.9456 - val_loss: 0.2301 - val_acc: 0.9473\n",
      "Epoch 69/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1965 - acc: 0.9452 - val_loss: 0.2324 - val_acc: 0.9444\n",
      "Epoch 70/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1888 - acc: 0.9465 - val_loss: 0.2332 - val_acc: 0.9469\n",
      "Epoch 71/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1946 - acc: 0.9467 - val_loss: 0.2260 - val_acc: 0.9473\n",
      "Epoch 72/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.1886 - acc: 0.9468 - val_loss: 0.2186 - val_acc: 0.9476\n",
      "Epoch 73/110\n",
      "34300/34300 [==============================] - 2s 65us/step - loss: 0.1890 - acc: 0.9471 - val_loss: 0.2333 - val_acc: 0.9465\n",
      "Epoch 74/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1926 - acc: 0.9459 - val_loss: 0.2251 - val_acc: 0.9469\n",
      "Epoch 75/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.1847 - acc: 0.9477 - val_loss: 0.2131 - val_acc: 0.9483\n",
      "Epoch 76/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1864 - acc: 0.9483 - val_loss: 0.2209 - val_acc: 0.9488\n",
      "Epoch 77/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1855 - acc: 0.9485 - val_loss: 0.2200 - val_acc: 0.9503\n",
      "Epoch 78/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1890 - acc: 0.9475 - val_loss: 0.2278 - val_acc: 0.9475\n",
      "Epoch 79/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1824 - acc: 0.9487 - val_loss: 0.2189 - val_acc: 0.9481\n",
      "Epoch 80/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1802 - acc: 0.9493 - val_loss: 0.2193 - val_acc: 0.9475\n",
      "Epoch 81/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1745 - acc: 0.9505 - val_loss: 0.2274 - val_acc: 0.9478\n",
      "Epoch 82/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1831 - acc: 0.9495 - val_loss: 0.2145 - val_acc: 0.9484\n",
      "Epoch 83/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1771 - acc: 0.9507 - val_loss: 0.2336 - val_acc: 0.9486\n",
      "Epoch 84/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1794 - acc: 0.9504 - val_loss: 0.2211 - val_acc: 0.9476\n",
      "Epoch 85/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.1748 - acc: 0.9508 - val_loss: 0.2232 - val_acc: 0.9497\n",
      "Epoch 86/110\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.1797 - acc: 0.9497 - val_loss: 0.2321 - val_acc: 0.9485\n",
      "Epoch 87/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1814 - acc: 0.9502 - val_loss: 0.2213 - val_acc: 0.9465\n",
      "Epoch 88/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1777 - acc: 0.9519 - val_loss: 0.2198 - val_acc: 0.9495\n",
      "Epoch 89/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1756 - acc: 0.9498 - val_loss: 0.2371 - val_acc: 0.9488\n",
      "Epoch 90/110\n",
      "34300/34300 [==============================] - 2s 68us/step - loss: 0.1781 - acc: 0.9501 - val_loss: 0.2250 - val_acc: 0.9491\n",
      "Epoch 91/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.1746 - acc: 0.9503 - val_loss: 0.2297 - val_acc: 0.9501\n",
      "Epoch 92/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1743 - acc: 0.9518 - val_loss: 0.2336 - val_acc: 0.9463\n",
      "Epoch 93/110\n",
      "34300/34300 [==============================] - 2s 67us/step - loss: 0.1743 - acc: 0.9499 - val_loss: 0.2228 - val_acc: 0.9495\n",
      "Epoch 94/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1684 - acc: 0.9517 - val_loss: 0.2410 - val_acc: 0.9483\n",
      "Epoch 95/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1684 - acc: 0.9534 - val_loss: 0.2228 - val_acc: 0.9489\n",
      "Epoch 96/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1746 - acc: 0.9527 - val_loss: 0.2203 - val_acc: 0.9479\n",
      "Epoch 97/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1705 - acc: 0.9517 - val_loss: 0.2268 - val_acc: 0.9502\n",
      "Epoch 98/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1704 - acc: 0.9522 - val_loss: 0.2256 - val_acc: 0.9483\n",
      "Epoch 99/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1717 - acc: 0.9506 - val_loss: 0.2375 - val_acc: 0.9461\n",
      "Epoch 100/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1632 - acc: 0.9538 - val_loss: 0.2319 - val_acc: 0.9490\n",
      "Epoch 101/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1650 - acc: 0.9540 - val_loss: 0.2337 - val_acc: 0.9479\n",
      "Epoch 102/110\n",
      "34300/34300 [==============================] - 2s 71us/step - loss: 0.1691 - acc: 0.9520 - val_loss: 0.2240 - val_acc: 0.9464\n",
      "Epoch 103/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1684 - acc: 0.9519 - val_loss: 0.2221 - val_acc: 0.9505\n",
      "Epoch 104/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1676 - acc: 0.9534 - val_loss: 0.2334 - val_acc: 0.9484\n",
      "Epoch 105/110\n",
      "34300/34300 [==============================] - 2s 72us/step - loss: 0.1623 - acc: 0.9530 - val_loss: 0.2358 - val_acc: 0.9490\n",
      "Epoch 106/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1653 - acc: 0.9543 - val_loss: 0.2533 - val_acc: 0.9463\n",
      "Epoch 107/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1595 - acc: 0.9552 - val_loss: 0.2305 - val_acc: 0.9478\n",
      "Epoch 108/110\n",
      "34300/34300 [==============================] - 2s 70us/step - loss: 0.1669 - acc: 0.9537 - val_loss: 0.2213 - val_acc: 0.9477\n",
      "Epoch 109/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1685 - acc: 0.9520 - val_loss: 0.2401 - val_acc: 0.9473\n",
      "Epoch 110/110\n",
      "34300/34300 [==============================] - 2s 69us/step - loss: 0.1597 - acc: 0.9549 - val_loss: 0.2435 - val_acc: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217a0484b00>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50,activation = 'relu',input_dim = 784))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(50,activation = 'relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(50,activation = 'relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(10,activation = 'softmax'))\n",
    "model2.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "model2.fit(train_x,train_y,epochs = 110,batch_size = 128,validation_data = (val_x,val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14700/14700 [==============================] - 0s 22us/step\n",
      "[0.24348815845591681, 0.9481632652899035]\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(val_x,val_y,batch_size = 128)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
